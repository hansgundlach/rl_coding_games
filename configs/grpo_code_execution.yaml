# configs/grpo_code_execution.yaml

# --- Model Settings ---
model:
  id: "Qwen/Qwen2.5-1.5B"  # Base model to use (will try to find 1.5B, then 3B in cache)
  cache_dir: "./model_cache"
  # local_files_only will be set by the script based on offline_mode detection

# --- LoRA Configuration ---
lora:
  task_type: "CAUSAL_LM"
  r: 16
  lora_alpha: 32
  target_modules: "all-linear" # Example: "q_proj,v_proj" or "all-linear"

# --- Training Arguments (GRPOConfig) ---
training_args:
  output_dir: "checkpoints/grpo_code_execution"
  learning_rate: 0.00002
  
  # Adaptive Batch/Sequence Lengths (Script will override based on GPU/Model size)
  # For V100 + 3B: batch_size=1, gradient_accumulation_steps=8, max_prompt_length=128, max_completion_length=256
  # For V100 + 1.5B: batch_size=4, gradient_accumulation_steps=2, max_prompt_length=256, max_completion_length=384
  # For A100/H100/Other: batch_size=8, gradient_accumulation_steps=2, max_prompt_length=512, max_completion_length=512
  per_device_train_batch_size: 8 # Default for other GPUs
  gradient_accumulation_steps: 2 # Default for other GPUs
  max_prompt_length: 512       # Default for other GPUs
  max_completion_length: 512   # Default for other GPUs

  num_generations: 2  # GRPO requires minimum 2
  optim: "adamw_8bit"
  num_train_epochs: 1
  
  # Precision (Script will set bf16/fp16 based on GPU support)
  # bf16: true/false
  # fp16: true/false
  
  gradient_checkpointing: False # Explicitly disabled
  dataloader_pin_memory: True   # Script will set to False for V100

  remove_unused_columns: False
  logging_steps: 1
  max_steps: 2  # Set to 2 for quick pipeline testing

# --- Weights & Biases Logging Settings ---
wandb:
  enabled: True                 # Set to False to completely disable W&B logging
  project_name_prefix: "qwen-code-execution-grpo" # Project name will be: prefix-timestamp

# --- Evaluation Settings (MBPP) ---
evaluation:
  enabled_initial: True       # Run initial MBPP evaluation
  enabled_final: True         # Run final MBPP evaluation
  # Further MBPP evaluator settings are managed in evaluation/mbpp_config.yaml or generated by create_eval_config_for_training

# --- Dataset Configuration ---
dataset:
  size: 1000  # Number of prompts in dataset
  
# --- Code Execution Settings ---
execution:
  timeout: 3  # Timeout in seconds for code execution
  debug_completions: 3  # Number of completions to show detailed debug info for

# --- Reward Function Settings ---
rewards:
  success_with_output: 1.0    # Code runs successfully and produces output
  success_no_output: 0.5      # Code runs successfully but no output  
  syntax_error: -0.5          # Code has syntax/indentation errors
  runtime_error: -1.0         # Code has runtime errors
  timeout_error: -1.0         # Code execution times out